%  LaTeX support: latex@mdpi.com 
%  For support, please attach all files needed for compiling as well as the log file, and specify your operating system, LaTeX version, and LaTeX editor.

%=================================================================
\documentclass[engproc,conferenceproceedings,submit,pdftex,moreauthors]{Definitions/mdpi} 

%--------------------
% Class Options:
%--------------------
%----------
% journal
%----------
% Choose between the following MDPI journals:
% acoustics, actuators, addictions, admsci, adolescents, aerobiology, aerospace, agriculture, agriengineering, agrochemicals, agronomy, ai, air, algorithms, allergies, alloys, analytica, analytics, anatomia, animals, antibiotics, antibodies, antioxidants, applbiosci, appliedchem, appliedmath, applmech, applmicrobiol, applnano, applsci, aquacj, architecture, arm, arthropoda, arts, asc, asi, astronomy, atmosphere, atoms, audiolres, automation, axioms, bacteria, batteries, bdcc, behavsci, beverages, biochem, bioengineering, biologics, biology, biomass, biomechanics, biomed, biomedicines, biomedinformatics, biomimetics, biomolecules, biophysica, biosensors, biotech, birds, bloods, blsf, brainsci, breath, buildings, businesses, cancers, carbon, cardiogenetics, catalysts, cells, ceramics, challenges, chemengineering, chemistry, chemosensors, chemproc, children, chips, cimb, civileng, cleantechnol, climate, clinpract, clockssleep, cmd, coasts, coatings, colloids, colorants, commodities, compounds, computation, computers, condensedmatter, conservation, constrmater, cosmetics, covid, crops, cryptography, crystals, csmf, ctn, curroncol, cyber, dairy, data, ddc, dentistry, dermato, dermatopathology, designs, devices, diabetology, diagnostics, dietetics, digital, disabilities, diseases, diversity, dna, drones, dynamics, earth, ebj, ecologies, econometrics, economies, education, ejihpe, electricity, electrochem, electronicmat, electronics, encyclopedia, endocrines, energies, eng, engproc, entomology, entropy, environments, environsciproc, epidemiologia, epigenomes, est, fermentation, fibers, fintech, fire, fishes, fluids, foods, forecasting, forensicsci, forests, foundations, fractalfract, fuels, future, futureinternet, futurepharmacol, futurephys, futuretransp, galaxies, games, gases, gastroent, gastrointestdisord, gels, genealogy, genes, geographies, geohazards, geomatics, geosciences, geotechnics, geriatrics, grasses, gucdd, hazardousmatters, healthcare, hearts, hemato, hematolrep, heritage, higheredu, highthroughput, histories, horticulturae, hospitals, humanities, humans, hydrobiology, hydrogen, hydrology, hygiene, idr, ijerph, ijfs, ijgi, ijms, ijns, ijpb, ijtm, ijtpp, ime, immuno, informatics, information, infrastructures, inorganics, insects, instruments, inventions, iot, j, jal, jcdd, jcm, jcp, jcs, jcto, jdb, jeta, jfb, jfmk, jimaging, jintelligence, jlpea, jmmp, jmp, jmse, jne, jnt, jof, joitmc, jor, journalmedia, jox, jpm, jrfm, jsan, jtaer, jvd, jzbg, kidneydial, kinasesphosphatases, knowledge, land, languages, laws, life, liquids, literature, livers, logics, logistics, lubricants, lymphatics, machines, macromol, magnetism, magnetochemistry, make, marinedrugs, materials, materproc, mathematics, mca, measurements, medicina, medicines, medsci, membranes, merits, metabolites, metals, meteorology, methane, metrology, micro, microarrays, microbiolres, micromachines, microorganisms, microplastics, minerals, mining, modelling, molbank, molecules, mps, msf, mti, muscles, nanoenergyadv, nanomanufacturing,\gdef\@continuouspages{yes}} nanomaterials, ncrna, ndt, network, neuroglia, neurolint, neurosci, nitrogen, notspecified, %%nri, nursrep, nutraceuticals, nutrients, obesities, oceans, ohbm, onco, %oncopathology, optics, oral, organics, organoids, osteology, oxygen, parasites, parasitologia, particles, pathogens, pathophysiology, pediatrrep, pharmaceuticals, pharmaceutics, pharmacoepidemiology,\gdef\@ISSN{2813-0618}\gdef\@continuous pharmacy, philosophies, photochem, photonics, phycology, physchem, physics, physiologia, plants, plasma, platforms, pollutants, polymers, polysaccharides, poultry, powders, preprints, proceedings, processes, prosthesis, proteomes, psf, psych, psychiatryint, psychoactives, publications, quantumrep, quaternary, qubs, radiation, reactions, receptors, recycling, regeneration, religions, remotesensing, reports, reprodmed, resources, rheumato, risks, robotics, ruminants, safety, sci, scipharm, sclerosis, seeds, sensors, separations, sexes, signals, sinusitis, skins, smartcities, sna, societies, socsci, software, soilsystems, solar, solids, spectroscj, sports, standards, stats, std, stresses, surfaces, surgeries, suschem, sustainability, symmetry, synbio, systems, targets, taxonomy, technologies, telecom, test, textiles, thalassrep, thermo, tomography, tourismhosp, toxics, toxins, transplantology, transportation, traumacare, traumas, tropicalmed, universe, urbansci, uro, vaccines, vehicles, venereology, vetsci, vibration, virtualworlds, viruses, vision, waste, water, wem, wevj, wind, women, world, youth, zoonoticdis 
% For posting an early version of this manuscript as a preprint, you may use "preprints" as the journal. Changing "submit" to "accept" before posting will remove line numbers.

%---------
% article
%---------
% The default type of manuscript is "article", but can be replaced by: 
% abstract, addendum, article, book, bookreview, briefreport, casereport, comment, commentary, communication, conferenceproceedings, correction, conferencereport, entry, expressionofconcern, extendedabstract, datadescriptor, editorial, essay, erratum, hypothesis, interestingimage, obituary, opinion, projectreport, reply, retraction, review, perspective, protocol, shortnote, studyprotocol, systematicreview, supfile, technicalnote, viewpoint, guidelines, registeredreport, tutorial
% supfile = supplementary materials

%----------
% submit
%----------
% The class option "submit" will be changed to "accept" by the Editorial Office when the paper is accepted. This will only make changes to the frontpage (e.g., the logo of the journal will get visible), the headings, and the copyright information. Also, line numbering will be removed. Journal info and pagination for accepted papers will also be assigned by the Editorial Office.

%------------------
% moreauthors
%------------------
% If there is only one author the class option oneauthor should be used. Otherwise use the class option moreauthors.

%---------
% pdftex
%---------
% The option pdftex is for use with pdfLaTeX. Remove "pdftex" for (1) compiling with LaTeX & dvi2pdf (if eps figures are used) or for (2) compiling with XeLaTeX.

%=================================================================
% MDPI internal commands - do not modify
\firstpage{1} 
\makeatletter 
\setcounter{page}{\@firstpage} 
\makeatother
\pubvolume{1}
\issuenum{1}
\articlenumber{0}
\pubyear{2023}
\copyrightyear{2023}
%\externaleditor{Academic Editor: Firstname Lastname}
\datereceived{ } 
\daterevised{ } % Comment out if no revised date
\dateaccepted{ } 
\datepublished{ } 
%\datecorrected{} % For corrected papers: "Corrected: XXX" date in the original paper.
%\dateretracted{} % For corrected papers: "Retracted: XXX" date in the original paper.
\hreflink{https://doi.org/} % If needed use \linebreak
%\doinum{}
%\pdfoutput=1 % Uncommented for upload to arXiv.org

%=================================================================
% Add packages and commands here. The following packages are loaded in our class file: fontenc, inputenc, calc, indentfirst, fancyhdr, graphicx, epstopdf, lastpage, ifthen, float, amsmath, amssymb, lineno, setspace, enumitem, mathpazo, booktabs, titlesec, etoolbox, tabto, xcolor, colortbl, soul, multirow, microtype, tikz, totcount, changepage, attrib, upgreek, array, tabularx, pbox, ragged2e, tocloft, marginnote, marginfix, enotez, amsthm, natbib, hyperref, cleveref, scrextend, url, geometry, newfloat, caption, draftwatermark, seqsplit
% cleveref: load \crefname definitions after \begin{document}

%=================================================================
% Please use the following mathematics environments: Theorem, Lemma, Corollary, Proposition, Characterization, Property, Problem, Example, ExamplesandDefinitions, Hypothesis, Remark, Definition, Notation, Assumption
%% For proofs, please use the proof environment (the amsthm package is loaded by the MDPI class).

%=================================================================
% Full title of the paper (Capitalized)
\Title{Title}

% MDPI internal command: Title for citation in the left column
\TitleCitation{Title}

% Author Orchid ID: enter ID or remove command
\newcommand{\orcidauthorA}{0000-0000-0000-000X} % Add \orcidA{} behind the author's name
%\newcommand{\orcidauthorB}{0000-0000-0000-000X} % Add \orcidB{} behind the author's name

% Authors, for the paper (add full first names)
\Author{Firstname Lastname $^{1,\dagger,\ddagger}$\orcidA{}, Firstname Lastname $^{2,\ddagger}$ and Firstname Lastname $^{2,}$*}

%\longauthorlist{yes}

% MDPI internal command: Authors, for metadata in PDF
\AuthorNames{Firstname Lastname, Firstname Lastname and Firstname Lastname}

% MDPI internal command: Authors, for citation in the left column
\AuthorCitation{Lastname, F.; Lastname, F.; Lastname, F.}
% If this is a Chicago style journal: Lastname, Firstname, Firstname Lastname, and Firstname Lastname.

% Affiliations / Addresses (Add [1] after \address if there is only one affiliation.)
\address{%
$^{1}$ \quad Affiliation 1; e-mail@e-mail.com\\
$^{2}$ \quad Affiliation 2; e-mail@e-mail.com}

% Contact information of the corresponding author
\corres{Correspondence: e-mail@e-mail.com; Tel.: (optional; include country code; if there are multiple corresponding authors, add author initials) +xx-xxxx-xxx-xxxx (F.L.)}

% Current address and/or shared authorship
\firstnote{Current address: Affiliation 3.} 
\secondnote{These authors contributed equally to this work.}
% The commands \thirdnote{} till \eighthnote{} are available for further notes

%\simplesumm{} % Simple summary

%\conference{} % An extended version of a conference paper

% Abstract (Do not insert blank lines, i.e. \\) 
\abstract{A single paragraph of about 200 words maximum. For research articles, abstracts should give a pertinent overview of the work. We strongly encourage authors to use the following style of structured abstracts, but without headings: (1) Background: place the question addressed in a broad context and highlight the purpose of the study; (2) Methods: describe briefly the main methods or treatments applied; (3) Results: summarize the article's main findings; (4) Conclusions: indicate the main conclusions or interpretations. The abstract should be an objective representation of the article, it must not contain results which are not presented and substantiated in the main text and should not exaggerate the main conclusions.}

% Keywords
\keyword{keyword 1; keyword 2; keyword 3 (List three to ten pertinent keywords specific to the article; yet reasonably common within the subject discipline.)} 

% The fields PACS, MSC, and JEL may be left empty or commented out if not applicable
%\PACS{J0101}
%\MSC{}
%\JEL{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Diversity
%\LSID{\url{http://}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Applied Sciences
%\featuredapplication{Authors are encouraged to provide a concise description of the specific application or a potential application of the work. This section is not mandatory.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Data
%\dataset{DOI number or link to the deposited data set if the data set is published separately. If the data set shall be published as a supplement to this paper, this field will be filled by the journal editors. In this case, please submit the data set as a supplement.}
%\datasetlicense{License under which the data set is made available (CC0, CC-BY, CC-BY-SA, CC-BY-NC, etc.)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Toxins
%\keycontribution{The breakthroughs or highlights of the manuscript. Authors can write one or two sentences to describe the most important part of the paper.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Encyclopedia
%\encyclopediadef{For entry manuscripts only: please provide a brief overview of the entry title instead of an abstract.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Advances in Respiratory Medicine
%\addhighlights{yes}
%\renewcommand{\addhighlights}{%

%\noindent This is an obligatory section in “Advances in Respiratory Medicine”, whose goal is to increase the discoverability and readability of the article via search engines and other scholars. Highlights should not be a copy of the abstract, but a simple text allowing the reader to quickly and simplified find out what the article is about and what can be cited from it. Each of these parts should be devoted up to 2~bullet points.\vspace{3pt}\\
%\textbf{What are the main findings?}
% \begin{itemize}[labelsep=2.5mm,topsep=-3pt]
% \item First bullet.
% \item Second bullet.
% \end{itemize}\vspace{3pt}
%\textbf{What is the implication of the main finding?}
% \begin{itemize}[labelsep=2.5mm,topsep=-3pt]
% \item First bullet.
% \item Second bullet.
% \end{itemize}
%}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

In 2022 at least 240 injuries an 10 deaths involving firefighters conduction firefighting operations in buildings were reported in the United States \cite{atemschutzunfälle.eu2023}. To improve safety while performing such a dangerous task, it can be helpful to determine the exact position of firefighters in indoor environments. This can shorten rescue time of injured personnel or help firefighters avoiding dangerous situations. To determine the position of a person in a building, a Pedestrian Dead Reckoning (PDR) approach is used. PDR describes a navigation technique used to estimate the position and movements of pedestrians in indoor or GPS-denied environments. It relies on sensors such as accelerometers, gyroscopes, and magnetometers integrated into wearable devices, smartphones or smartwatches. By continuously tracking a pedestrian's step counts, stride length, and heading changes, PDR algorithms can calculate their relative displacement from a known starting point. Other means of PDR include simultanious locating and mapping (SLAM)\cite{lu2019}, magnetic field mapping \cite{wang2016} or magnetic triangulation \cite{arumugam2020}. While PDR is most commonly used in Fitness and Smart devices, applications also include Robotics, Augmented Reality and Security.\\

For an application in firefighting operations, many of the aforementioned PDR methods are not feasible. While radio tracking \cite{cong2023} or magnetic mapping \cite{wang2016} yield good results, they are technologies that have to be set up before use. It may be possible to achieve this for some large buildings, however it would be not feasible to do for every building in an area where a fire might occur. For firefighters to being able to use the system in any indoor environment, a completely stand-alone, body-worn device is required. Stand-alone PDR systems often rely on a form of step-detection \cite{hou2021}. While algorithms based on step-detection yield good results when walking, movement occurring in a firefighting application includes more dynamic activities like crouching that are hard to detect by a step-detection algorithm. Therefore, a secondary sensor measuring position or velocity is necessary to improve accuracy in those cases. A common sensor chosen for this is a Light Detection and Ranging (LIDAR) sensor \cite{wang2016}. While this approach might yield good results, tests have shown that distance readings of LIDAR systems are heavily influenced by smoke particles and therefore are not usable in a firefighting environment. \\

This paper presents an approach for enhanced PDR. The step-detection algorithm is extended with a secondary sensor. The sensor chosen for is a stereo tracking camera. This device is able to visually determine velocity and position relative to a starting point and is combined with a step-detection algorithm. Position and velocity data from the tracking camera and position data from the step-detection are then fused in a Kalman filter to improve accuracy.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Materials and Methods}

The PDR relies on a sensor data fusion algorithm combining position data estimated by a step-detection algorithm and the velocity and position data estimated with a tracking camera.\\

\subsection{Step-Detection}
Step-detection describes the process of detecting or counting a persons steps by measuring and analysing the accelerations of a body-worn inertial measurement unit (IMU). The most common ways of step-detection is analysing the vertical acceleration signal and using peak-detection, zero-crossing detection or flat zone detection. Since flat zone detection only works for foot mounted sensors and peak-detection accuracy is dependend on a persons walking speed \cite{shin2007}, a zero-crossing detection approach is chosen. The step-detection presented in this paper consists of a zero-crossing detection \cite{zhao2022} enhanced with a threshold-crossing detection to improve the detection robustness: The vertical acceleration signal firstly is filtered in a Lowpass filter (LPF) to remove the high frequency parts of the signal that occur during movement. Since the frequency range of normal human walking is in the range of $1-5\mathrm{Hz}$, the edge frequency of the LPF set to $10 \mathrm{Hz}$. The signal is then analysed by the step-detection algorithm: First the acceleration has to pass a set positive threshold $th_{max}$. After $th_{max}$ is passed, a zero crossing has to be detected and the acceleration has to fall below a negative threshold $th_{min}$. If $th_{min}$ is passed and another zero-crossing is detected, the step is counted as completed. If the step is not completed in a set time or the negative threshold is not passed the step-detection logic is reset and no step is counted.   \\ 

%\begin{figure}[h!]
%	\centering
%	\includegraphics[width=0.5\textwidth,height=5cm]{test.png}
%	\caption{Acceleration Signal during one step}
%\end{figure}

 After a step is detected, the length of the step is added to the last known position. The step length is estimated with the equation proposed by Weinberg \cite{weinberg2002}:
 \begin{equation}
 	d = \sqrt[4]{A_{max}-A_{min}}\cdot n\cdot k
 \end{equation}
 where $d$ is the distance travelled, $A_{max}$ is the maximum acceleration during a single step, $A_{min}$ is the minimal acceleration during a step, $n$ is the number of steps taken and $k$ is a constant for unit conversion. This method of step length estimation was chosen because it produces accurate estimates with low computational effort compared to other algorithms \cite{petukhov2022, shin2007, zizzo2017}. The step then is added in the direction of movement which is determined by the heading angle measured by the IMU. It is assumed, that because of limited sight and movement during an indoor operation with self-contained breathing apparatus (scba), firefighters will in most cases move in the direction their body is pointed. Since the IMU is mounted on the air tank of the firefighter, the orientation of the IMU equals the direction of movement.\\
 
  % Coordinate System/ Reference frame -> Appendix?
 For the measurements to be interpreted correctly, a global reference system $n$ has to be determined. This coordinate system is set by the staring position of the tracked individual, where the starting point represents the $\left[0\;0\;0\right]$ coordinate origin and the direction the individual is looking the X-Axis (Heading angle $\alpha_h = 0$). The Z-Axis is the normal vector of a imagined plane the individual is standing on. The body reference frame $b$ of the two devices has to be rotated  into the global reference frame $n$. Since the tracking camera defines its starting-point and coordinate system by the same principles, the camera coordinate transformation gets performed by the device itself. For the acceleration values of the IMU, a coordinate transformation has to be performed: The acceleration measured in the body coordinate frame has to be rotated into the global reference frame. 
 \begin{equation}
 	\begin{bmatrix}
 		a_{x_n}\\
 		a_{y_n}\\
 		a_{z_n}
 	\end{bmatrix} = R_n^b \cdot
 	\begin{bmatrix}
 		a_{x_n}\\
 		a_{y_n}\\
 		a_{z_n}
 	\end{bmatrix}
 \end{equation}
 with the $R_{zxz}$ Transformation Matrix $R_n^b$: [QUELLE]
 \begin{equation}
 	R_n^b =\\
 	\begin{bmatrix}
 		s_1  - \cos \beta s_2 &
 		s_3  + \cos \beta s_4 &
 		\sin \beta \sin \gamma \\
 		- s_4 -  \cos \beta s_3 &
 		- s_2 +  \cos \beta s_1 &
 		\sin \beta  \cos \gamma  \\
 		\sin \alpha \sin \beta &
 		-\cos \alpha \sin \beta &
 		\cos \beta
 	\end{bmatrix}	
 \end{equation}
 where $s_1 = \cos \alpha \cos \gamma$, $s_2 = \sin\alpha\sin\gamma$, $s_3 =  \sin \alpha \cos \gamma$ and $s_4 = \cos \alpha \sin \gamma$\\
 

 
 
 \subsection{Tracking Camera}
 For the secondary sensor a stereo tracking camera is chosen. Stereo tracking cameras work similarly to the human eye: The device has two calibrated cameras that are placed with a distance to each other and are horizontally aligned. By measuring the displacement of a tracked object between the two cameras, the distance to the object can be calculated. Figure \ref{fig:cmaera} shows the two aligned cameras.
% To measure the distance $d_{obj}$, the angles $\theta$, $\beta$ and $\gamma$ need to be determined. Angle $\theta$ and $\beta$ are calculated by measuring the position of the tracked object in the cameras field of view \cite{zaarane2020}. Angle $\gamma$ can be determinded by:
% \begin{equation}
% 	\gamma = 180\deg - \theta -\beta
% \end{equation}
% With angle $\gamma$ the distance to the tracked object then can be determined by: [Fehlt] 
 Doing this for multiple objects and repeating this process every frame, the position and average velocity can be calculated.
 Some camera models also use a infrared projected grid of dots to determine depth of the surrounding environment and can create a 3D profile.
 
 

 
 

 
 
\subsection{Sensor-Data Fusion}
 % Sensordata Fusion
To combine the different sensor measurements, a Kalman filter is used. The Kalman filter is an optimal recursive algorithm used in control systems and data assimilation to estimate the state of a dynamic system from a series of noisy measurements. It maintains a probabilistic representation of the system's state, combining predictions from a mathematical model and observations to obtain a more accurate and stable estimation. The filter operates in two steps: the prediction step, where the system's state $\hat{x}$ is predicted with the state transition model. And the update step, where measurements are used to correct the predicted state by computing the Kalman gain, which balances the model's predictions and the actual measurements. This process continually refines the state estimate as new data becomes available, making it robust against noise and capable of handling real-time applications. The state transition model used assumes a constant acceleration between updates. By tuning the covariance matrices of the Kalman filter, the accuracy of the predictions and measurement updates can be further improved.\\

[Fehlt Beschreibung des Modells]\\


\begin{equation}
	\begin{bmatrix}
		A_k \\
		V_k\\
		P_k
	\end{bmatrix} = 
	\begin{bmatrix}
		A_{k-1}\\
		s_2 t \cdot A_{k-1}^3  \\
		s_2 t \cdot A_{k-1}^3 + s_2 t^2\cdot V_{k-1}^3
	\end{bmatrix}
	\label{SystemState}
\end{equation}

 The position estimates from the tracking camera and the step detection have to be combined in a way that takes their quality into account. The quality of the measurements is determined by:

\begin{itemize}
	\item Time since last step was detected. It is assumed that the accuracy of the estimated position by the step-detection algorithm deterioates with time if no successing step is detected.
	\item Tracking Confidence of the Tracking Camera. The Tracking Camera is able to calculate and return a confidence value of the tracking results. 
\end{itemize}

For the step detection, three states are proposed: the time after the last step detection event is smaller or greater than 0.5 seconds or the event happened longer than 3 seconds ago. The assumption is, that after that time it can be assumed, that movement has occurred but was not detected by the step detection algorithm.\\


The tracking confidence returned by the camera can reach four states from zero to three, where three is the highest confidence and zero the lowest.
To combine the two measurements and take the confidence markers into account, a decision matrix is proposed. The decision matrix includes nine cases. This approach was influenced by the approach chosen in \cite{caron2006}. Goal of this approach is to weight and combine the inputs to achieve the best measurement.  If the quality of both markers is bad, the step detection gets highly favoured, since it provides stable results during walking, even in zero visibility environments. If the tracking confidence is high, the tracking camera measurements get slightly favoured. This is because in theory the tracking cameras results will be better since it produces continuos position updates and can track the position regardless of the type of movement Figure \ref{fig_confidence} shows a graphical representation of the decision matrix. The combination of the measurements is performed before they are used in the Kalman Filter. A combination factor $\alpha$ is calculated from the decision matrix and used for the combination of the two measurements.
\begin{equation}
	x_{k} = \alpha\cdot x_{step} + (1-\alpha)\cdot x_{camera}
\end{equation}  
where $x_{k}$ is the position measurement input, $x_{step}$ is the position estimate produced by the step-detection and $x_{camera}$ is the position estimate from the tracking camera. The same calculation is performed for the y-axis.
The Kalman filter is implemented in Matlab using the Tracking Kalman filter library. \\

[Bild Schema Algorithmus]

%\begin{figure}[h!]
%	\centering
%	\includegraphics[width=\textwidth,height=7cm]{test.png}
%	\caption{Test}
%\end{figure}

% Description Experiment
\subsection{Application and Verification}
 % Sensor assembly
 
A low cost IMU is chosen to measure the acceleration. The used deviced is the Bosch Sensortech BNO055 absolute orientation sensor. The device measures acceleration in three axes and provides absolute heading data by measuring the earths magnetic field. The sensor can provide a filtered heading angle.\\
  
The tracking camera chosen is the RealSense T265 stereo tracking camera. Its main advantage against competitors is the on-chip data processing, meaning that no other means of interpreting the data is necessary and the velocity and position data can be directly used for the sensor data fusion. By using parts of the infrared spectrum the camera also can produce accurate tracking results in environments with bad lighting.\\
  
For experimantal verification of the system, a wearable sensor assembly is designed. Both sensors are mounted to the backplate of a self-contained breathing apparatus. This design is chosen to imitate a application in a firefighting setting, where the sensors would be mounted on the pressurized air tank of the scba. For this a 3D printed spacer is mounted to mount the sensors at the right distance. A weigth is added to represent the weigth of the scba air tank. The camera and IMU are housed to protect the electronics from damage.  Figure \ref{fig:Assembly} shows the experimental setup.\\


To evaluate sensor and algorithm performance, tests on a set trajectory are performed. To quantify the results, the deviation from the true path is evaluated at set control points. The control points represent changes in heading in the true trajectory. This allows a simple comparison between the true path and the measured path. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}



\begin{table}[H] 
\caption{This is a table caption. Tables should be placed in the main text near to the first time they are~cited.\label{tab1}}
\newcolumntype{C}{>{\centering\arraybackslash}X}
\begin{tabularx}{\textwidth}{CCC}
\toprule
\textbf{Title 1}	& \textbf{Title 2}	& \textbf{Title 3}\\
\midrule
Entry 1		& Data			& Data\\
Entry 2		& Data			& Data \textsuperscript{1}\\
\bottomrule
\end{tabularx}
\noindent{\footnotesize{\textsuperscript{1} Tables may have a footer.}}
\end{table}

The text continues here (Figure~\ref{fig2} and Table~\ref{tab2}).

% Example of a figure that spans the whole page width. The same concept works for tables, too.
\begin{figure}[H]
\begin{adjustwidth}{-\extralength}{0cm}
\centering
\includegraphics[width=15.5cm]{Definitions/logo-mdpi}
\end{adjustwidth}
\caption{This is a wide figure.\label{fig2}}
\end{figure}  

\begin{table}[H]
\caption{This is a wide table.\label{tab2}}
	\begin{adjustwidth}{-\extralength}{0cm}
		\newcolumntype{C}{>{\centering\arraybackslash}X}
		\begin{tabularx}{\fulllength}{CCCC}
			\toprule
			\textbf{Title 1}	& \textbf{Title 2}	& \textbf{Title 3}     & \textbf{Title 4}\\
			\midrule
\multirow[m]{3}{*}{Entry 1 *}	& Data			& Data			& Data\\
			  	                   & Data			& Data			& Data\\
			             	      & Data			& Data			& Data\\
                   \midrule
\multirow[m]{3}{*}{Entry 2}    & Data			& Data			& Data\\
			  	                  & Data			& Data			& Data\\
			             	     & Data			& Data			& Data\\
                   \midrule
\multirow[m]{3}{*}{Entry 3}    & Data			& Data			& Data\\
			  	                 & Data			& Data			& Data\\
			             	    & Data			& Data			& Data\\
                  \midrule
\multirow[m]{3}{*}{Entry 4}   & Data			& Data			& Data\\
			  	                 & Data			& Data			& Data\\
			             	    & Data			& Data			& Data\\
			\bottomrule
		\end{tabularx}
	\end{adjustwidth}
	\noindent{\footnotesize{* Tables may have a footer.}}
\end{table}

%\begin{listing}[H]
%\caption{Title of the listing}
%\rule{\columnwidth}{1pt}
%\raggedright Text of the listing. In font size footnotesize, small, or normalsize. Preferred format: left aligned and single spaced. Preferred border format: top border line and bottom border line.
%\rule{\columnwidth}{1pt}
%\end{listing}

Text.

Text.

\subsection{Formatting of Mathematical Components}

This is the example 1 of equation:
\begin{linenomath}
\begin{equation}
a = 1,
\end{equation}
\end{linenomath}
the text following an equation need not be a new paragraph. Please punctuate equations as regular text.
%% If the documentclass option "submit" is chosen, please insert a blank line before and after any math environment (equation and eqnarray environments). This ensures correct linenumbering. The blank line should be removed when the documentclass option is changed to "accept" because the text following an equation should not be a new paragraph.

This is the example 2 of equation:
\begin{adjustwidth}{-\extralength}{0cm}
\begin{equation}
a = b + c + d + e + f + g + h + i + j + k + l + m + n + o + p + q + r + s + t + u + v + w + x + y + z
\end{equation}
\end{adjustwidth}

% Example of a page in landscape format (with table and table footnote).
%\startlandscape
%\begin{table}[H] %% Table in wide page
%\caption{This is a very wide table.\label{tab3}}
%	\begin{tabularx}{\textwidth}{CCCC}
%		\toprule
%		\textbf{Title 1}	& \textbf{Title 2}	& \textbf{Title 3}	& \textbf{Title 4}\\
%		\midrule
%		Entry 1		& Data			& Data			& This cell has some longer content that runs over two lines.\\
%		Entry 2		& Data			& Data			& Data\textsuperscript{1}\\
%		\bottomrule
%	\end{tabularx}
%	\begin{adjustwidth}{+\extralength}{0cm}
%		\noindent\footnotesize{\textsuperscript{1} This is a table footnote.}
%	\end{adjustwidth}
%\end{table}
%\finishlandscape


Please punctuate equations as regular text. Theorem-type environments (including propositions, lemmas, corollaries etc.) can be formatted as follows:
%% Example of a theorem:
\begin{Theorem}
Example text of a theorem.
\end{Theorem}

The text continues here. Proofs must be formatted as follows:

%% Example of a proof:
\begin{proof}[Proof of Theorem 1]
Text of the proof. Note that the phrase ``of Theorem 1'' is optional if it is clear which theorem is being referred to.
\end{proof}
The text continues here.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}

Authors should discuss the results and how they can be interpreted from the perspective of previous studies and of the working hypotheses. The findings and their implications should be discussed in the broadest context possible. Future research directions may also be highlighted.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}

This section is not mandatory, but can be added to the manuscript if the discussion is unusually long or complex.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Patents}

This section is not mandatory, but may be added if there are patents resulting from the work reported in this manuscript.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{6pt} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
%\supplementary{The following supporting information can be downloaded at:  \linksupplementary{s1}, Figure S1: title; Table S1: title; Video S1: title.}

% Only for journal Methods and Protocols:
% If you wish to submit a video article, please do so with any other supplementary material.
% \supplementary{The following supporting information can be downloaded at: \linksupplementary{s1}, Figure S1: title; Table S1: title; Video S1: title. A supporting video article is available at doi: link.}

% Only for journal Hardware:
% If you wish to submit a video article, please do so with any other supplementary material.
% \supplementary{The following supporting information can be downloaded at: \linksupplementary{s1}, Figure S1: title; Table S1: title; Video S1: title.\vspace{6pt}\\
%\begin{tabularx}{\textwidth}{lll}
%\toprule
%\textbf{Name} & \textbf{Type} & \textbf{Description} \\
%\midrule
%S1 & Python script (.py) & Script of python source code used in XX \\
%S2 & Text (.txt) & Script of modelling code used to make Figure X \\
%S3 & Text (.txt) & Raw data from experiment X \\
%S4 & Video (.mp4) & Video demonstrating the hardware in use \\
%... & ... & ... \\
%\bottomrule
%\end{tabularx}
%}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\authorcontributions{For research articles with several authors, a short paragraph specifying their individual contributions must be provided. The following statements should be used ``Conceptualization, X.X. and Y.Y.; methodology, X.X.; software, X.X.; validation, X.X., Y.Y. and Z.Z.; formal analysis, X.X.; investigation, X.X.; resources, X.X.; data curation, X.X.; writing---original draft preparation, X.X.; writing---review and editing, X.X.; visualization, X.X.; supervision, X.X.; project administration, X.X.; funding acquisition, Y.Y. All authors have read and agreed to the published version of the manuscript.'', please turn to the  \href{http://img.mdpi.org/data/contributor-role-instruction.pdf}{CRediT taxonomy} for the term explanation. Authorship must be limited to those who have contributed substantially to the work~reported.}

\funding{Please add: ``This research received no external funding'' or ``This research was funded by NAME OF FUNDER grant number XXX.'' and  and ``The APC was funded by XXX''. Check carefully that the details given are accurate and use the standard spelling of funding agency names at \url{https://search.crossref.org/funding}, any errors may affect your future funding.}

\institutionalreview{In this section, you should add the Institutional Review Board Statement and approval number, if relevant to your study. You might choose to exclude this statement if the study did not require ethical approval. Please note that the Editorial Office might ask you for further information. Please add “The study was conducted in accordance with the Declaration of Helsinki, and approved by the Institutional Review Board (or Ethics Committee) of NAME OF INSTITUTE (protocol code XXX and date of approval).” for studies involving humans. OR “The animal study protocol was approved by the Institutional Review Board (or Ethics Committee) of NAME OF INSTITUTE (protocol code XXX and date of approval).” for studies involving animals. OR “Ethical review and approval were waived for this study due to REASON (please provide a detailed justification).” OR “Not applicable” for studies not involving humans or animals.}

\informedconsent{Any research article describing a study involving humans should contain this statement. Please add ``Informed consent was obtained from all subjects involved in the study.'' OR ``Patient consent was waived due to REASON (please provide a detailed justification).'' OR ``Not applicable'' for studies not involving humans. You might also choose to exclude this statement if the study did not involve humans.

Written informed consent for publication must be obtained from participating patients who can be identified (including by the patients themselves). Please state ``Written informed consent has been obtained from the patient(s) to publish this paper'' if applicable.}

\dataavailability{We encourage all authors of articles published in MDPI journals to share their research data. In this section, please provide details regarding where data supporting reported results can be found, including links to publicly archived datasets analyzed or generated during the study. Where no new data were created, or where data is unavailable due to privacy or ethical restrictions, a statement is still required. Suggested Data Availability Statements are available in section ``MDPI Research Data Policies'' at \url{https://www.mdpi.com/ethics}.} 

% Only for journal Nursing Reports
%\publicinvolvement{Please describe how the public (patients, consumers, carers) were involved in the research. Consider reporting against the GRIPP2 (Guidance for Reporting Involvement of Patients and the Public) checklist. If the public were not involved in any aspect of the research add: ``No public involvement in any aspect of this research''.}

% Only for journal Nursing Reports
%\guidelinesstandards{Please add a statement indicating which reporting guideline was used when drafting the report. For example, ``This manuscript was drafted against the XXX (the full name of reporting guidelines and citation) for XXX (type of research) research''. A complete list of reporting guidelines can be accessed via the equator network: \url{https://www.equator-network.org/}.}

\acknowledgments{In this section you can acknowledge any support given which is not covered by the author contribution or funding sections. This may include administrative and technical support, or donations in kind (e.g., materials used for experiments).}

\conflictsofinterest{Declare conflicts of interest or state ``The authors declare no conflict of interest.'' Authors must identify and declare any personal circumstances or interest that may be perceived as inappropriately influencing the representation or interpretation of reported research results. Any role of the funders in the design of the study; in the collection, analyses or interpretation of data; in the writing of the manuscript; or in the decision to publish the results must be declared in this section. If there is no role, please state ``The funders had no role in the design of the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript; or in the decision to publish the results''.} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Optional
\sampleavailability{Samples of the compounds ... are available from the authors.}

%% Only for journal Encyclopedia
%\entrylink{The Link to this entry published on the encyclopedia platform.}

\abbreviations{Abbreviations}{
The following abbreviations are used in this manuscript:\\

\noindent 
\begin{tabular}{@{}ll}
MDPI & Multidisciplinary Digital Publishing Institute\\
DOAJ & Directory of open access journals\\
TLA & Three letter acronym\\
LD & Linear dichroism
\end{tabular}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Optional
\appendixtitles{no} % Leave argument "no" if all appendix headings stay EMPTY (then no dot is printed after "Appendix A"). If the appendix sections contain a heading then change the argument to "yes".
\appendixstart
\appendix
\section[\appendixname~\thesection]{}
\subsection[\appendixname~\thesubsection]{}
The appendix is an optional section that can contain details and data supplemental to the main text---for example, explanations of experimental details that would disrupt the flow of the main text but nonetheless remain crucial to understanding and reproducing the research shown; figures of replicates for experiments of which representative data are shown in the main text can be added here if brief, or as Supplementary Data. Mathematical proofs of results not central to the paper can be added as an appendix.

\begin{table}[H] 
\caption{This is a table caption.\label{tab5}}
\newcolumntype{C}{>{\centering\arraybackslash}X}
\begin{tabularx}{\textwidth}{CCC}
\toprule
\textbf{Title 1}	& \textbf{Title 2}	& \textbf{Title 3}\\
\midrule
Entry 1		& Data			& Data\\
Entry 2		& Data			& Data\\
\bottomrule
\end{tabularx}
\end{table}

\section[\appendixname~\thesection]{}
All appendix sections must be cited in the main text. In the appendices, Figures, Tables, etc. should be labeled, starting with ``A''---e.g., Figure A1, Figure A2, etc.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{adjustwidth}{-\extralength}{0cm}
%\printendnotes[custom] % Un-comment to print a list of endnotes

\reftitle{References}

% Please provide either the correct journal abbreviation (e.g. according to the “List of Title Word Abbreviations” http://www.issn.org/services/online-services/access-to-the-ltwa/) or the full name of the journal.
% Citations and References in Supplementary files are permitted provided that they also appear in the reference list here. 

%=====================================
% References, variant A: external bibliography
%=====================================
%\bibliography{bibConf}

%=====================================
% References, variant B: internal bibliography
%=====================================
\begin{thebibliography}{999}
\bibitem{arumugam2020}
Darmindra~D. Arumugam, Peter Littlewood, Nicholas Peng, and Divyam Mishra.
\newblock Long-{{Range Through-the-Wall Magnetoquasistatic Coupling}} and
{{Application}} to {{Indoor Position Sensing}}.
\newblock 19(3):507--511.

\bibitem{atemschutzunfalle.eu2023}
Atemschutzunfälle.eu.
\newblock Unfälle in {{Amerika}}.

\bibitem{caron2006}
Francois Caron, Emmanuel Duflos, Denis Pomorski, and Philippe Vanheeghe.
\newblock {{GPS}}/{{IMU}} data fusion using multisensor {{Kalman}} filtering:
Introduction of contextual aspects.
\newblock 7(2):221--230.

\bibitem{cong2023}
Li~Cong, Jingnan Tian, and Honglei Qin.
\newblock Practical {{Step Length Estimation Combining FM Radio Signal}} and
{{Accelerometer}}.
\newblock 72:1--13.

\bibitem{hajati2021}
N.~Hajati and A.~Rezaeizadeh.
\newblock A {{Wearable Pedestrian Localization}} and {{Gait Identification
		System Using Kalman Filtered Inertial Data}}.
\newblock 70.
\newblock Cited By :13.

\bibitem{hou2021}
X.~Hou and J.~Bergmann.
\newblock Pedestrian {{Dead Reckoning}} with {{Wearable Sensors}}: {{A
		Systematic Review}}.
\newblock 21(1):143--152.
\newblock Cited By :52.

\bibitem{jen2023}
Y.-H. Jen, C.-H. Huang, S.~Tsai, and K.-W. Chiang.
\newblock A {{MULTI-IMU BASED SELF-CONTAINED PEDESTRIAN NAVIGATION ALGORITHM}}.
\newblock XLVIII-1/W1-2023:603--608.
\newblock Multiple IMUs improve heading estimatioon,.

\bibitem{lu2019}
C.~Lu, H.~Uchiyama, D.~Thomas, A.~Shimada, and R.-I. Taniguchi.
\newblock Indoor positioning system based on chest-mounted {{IMU}}.
\newblock 19(2).
\newblock Cited By :47.

\bibitem{petukhov2022}
Nikita~I. Petukhov, Vladimir~N. Zamolodchikov, Alexander~P. Malyshev,
Tatyana~A. Brovko, Sergey~A. Serov, and Ilya~V. Korogodin.
\newblock Synthesis of {{PDR Algorithm}} and {{Experimental Estimation}} of
{{Accuracy}} of {{Step Length Estimation Methods}}.
\newblock In {\em 2022 4th {{International Youth Conference}} on {{Radio
			Electronics}}, {{Electrical}} and {{Power Engineering}} ({{REEPE}})}, pages
1--5. {IEEE}.

\bibitem{sadruddin2020}
Hamza Sadruddin, Ahmed Mahmoud, and Mohamed~M. Atia.
\newblock Enhancing {{Body-Mounted LiDAR SLAM}} using an {{IMU-based Pedestrian
		Dead Reckoning}} ({{PDR}}) {{Model}}.
\newblock In {\em 2020 {{IEEE}} 63rd {{International Midwest Symposium}} on
	{{Circuits}} and {{Systems}} ({{MWSCAS}})}, pages 901--904.

\bibitem{shin2007}
S.~H. Shin, C.~G. Park, J.~W. Kim, H.~S. Hong, and J.~M. Lee.
\newblock Adaptive {{Step Length Estimation Algorithm Using Low-Cost MEMS
		Inertial Sensors}}.
\newblock In {\em 2007 {{IEEE Sensors Applications Symposium}}}, pages 1--5.

\bibitem{wang2016}
Qu~Wang, Haiyong Luo, Fang Zhao, and Wenhua Shao.
\newblock An indoor self-localization algorithm using the calibration of the
online magnetic fingerprints and indoor landmarks.
\newblock In {\em 2016 {{International Conference}} on {{Indoor Positioning}}
	and {{Indoor Navigation}} ({{IPIN}})}, pages 1--8.

\bibitem{weinberg2002}
Harvey Weinberg.
\newblock Using the {{ADXL202}} in {{Pedometer}} and {{Personal Navigation
		Applications}}.

\bibitem{wu2022}
Yibin Wu, Jian Kuang, and Xiaoji Niu.
\newblock Wheel-{{INS2}}: {{Multiple MEMS IMU-based Dead Reckoning System}} for
{{Wheeled Robots}} with {{Evaluation}} of {{Different IMU Configurations}}.
\newblock Comment: Accepted to IEEE Transactions on Intelligent Transportation
Systems.

\bibitem{zaarane2020}
Abdelmoghit Zaarane, Ibtissam Slimani, Wahban Al~Okaishi, Issam Atouf, and
Abdellatif Hamdoun.
\newblock Distance measurement system for autonomous vehicles using stereo
camera.
\newblock 5:100016.

\bibitem{zhao2021}
Tianyi Zhao and Mohammed~Jalal Ahamed.
\newblock Pseudo-{{Zero Velocity Re-Detection Double Threshold Zero-Velocity
		Update}} ({{ZUPT}}) for {{Inertial Sensor-Based Pedestrian Navigation}}.
\newblock 21(12):13772--13785.

\bibitem{zhao2022}
Yue Zhao, Jianyong Wang, and Chengyong Duan.
\newblock Design and application research of mine underground disaster relief
personnel positioning system based on {{MEMS}} sensor.
\newblock In {\em International {{Conference}} on {{Neural Networks}},
	{{Information}}, and {{Communication Engineering}} ({{NNICE}} 2022)}, volume
12258, pages 695--704. {SPIE}.

\bibitem{zizzo2017}
Giulio Zizzo and Lei Ren.
\newblock Position {{Tracking During Human Walking Using}} an {{Integrated
		Wearable Sensing System}}.
\newblock 17(12):2866.
\end{thebibliography}

% If authors have biography, please use the format below
%\section*{Short Biography of Authors}
%\bio
%{\raisebox{-0.35cm}{\includegraphics[width=3.5cm,height=5.3cm,clip,keepaspectratio]{Definitions/author1.pdf}}}
%{\textbf{Firstname Lastname} Biography of first author}
%
%\bio
%{\raisebox{-0.35cm}{\includegraphics[width=3.5cm,height=5.3cm,clip,keepaspectratio]{Definitions/author2.jpg}}}
%{\textbf{Firstname Lastname} Biography of second author}

% For the MDPI journals use author-date citation, please follow the formatting guidelines on http://www.mdpi.com/authors/references
% To cite two works by the same author: \citeauthor{ref-journal-1a} (\citeyear{ref-journal-1a}, \citeyear{ref-journal-1b}). This produces: Whittaker (1967, 1975)
% To cite two works by the same author with specific pages: \citeauthor{ref-journal-3a} (\citeyear{ref-journal-3a}, p. 328; \citeyear{ref-journal-3b}, p.475). This produces: Wong (1999, p. 328; 2000, p. 475)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% for journal Sci
%\reviewreports{\\
%Reviewer 1 comments and authors’ response\\
%Reviewer 2 comments and authors’ response\\
%Reviewer 3 comments and authors’ response
%}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\PublishersNote{}
\end{adjustwidth}
\end{document}

